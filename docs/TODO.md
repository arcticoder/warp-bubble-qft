# TODO — Publishable-Grade Verification & Extensions (warp-bubble-qft)

This file is a working roadmap to turn the current research-stage framework into a reproducible, publishable-quality result (positive, negative/null, or methods/benchmark paper).

Guiding principle: **treat all headline claims as hypotheses** until reproduced under controlled sweeps with archived configs, versions, and deterministic outputs.

---

## Status (as of 2026-01-21)

- Completed artifacts and notes:
  - `results/REPRODUCIBILITY.md`
  - `results/ANALYSIS_SUMMARY.md`
  - `results/sensitivity_analysis_*.json`
  - `results/qi_scan.png`, `results/energy_density_profile.png`
  - `results/monte_carlo_feasibility.png`, `results/*_sensitivity.png`
- Verification scripts added:
  - `verify_qi_energy_density.py` (supports `--save-plots` and `--scan`)
  - `sensitivity_analysis.py` (supports `--save-results` and `--save-plots`)

From here, prioritize tasks that resolve the core discrepancy (the “1083× / 99.9%” headline), then build rigor via nonlinear/iterative backreaction, toy evolution, and causality screening.

---

## 0) Reproducibility Baseline (completed; keep current)

- [x] Record runtime environment (see `results/REPRODUCIBILITY.md`)
- [x] Establish a single “golden run” command + frozen config
- [x] Define output artifacts to archive (logs/JSON/plots are in `results/`)

Deliverable: a short reproducibility note (what to run, what you get, hashes).

---

## 1) Reproduce & Verify Core Claims (focus here next)

### 1.1 Resolve the “1083× / 99.9%” energy optimization discrepancy (PRIORITY)

Observed so far:
- The *pipeline* energy requirement reduction reproduced is ~30× (e.g., quick-check ~29×; scans show all points feasible).
- The **1083× / 3.80 GJ → 3.5 MJ** headline is generated by cross-repository computational accounting (`ENERGY_OPTIMIZATION_REPORT.json`, `src/energy/cross_repository_energy_integration.py`).

This task is to **reconcile definitions** and either:
(A) reproduce 1083× under a clear definition within the pipeline, or
(B) update documentation to clearly separate “computational energy optimization” from “warp bubble feasibility ratio”.

- [x] Define the quantities precisely and in writing
  - Pipeline: "base energy requirement" = dimensionless feasibility ratio (target <= 1) after VdB-Natário + LQG
  - Cross-repo report: "baseline_energy_GJ" = computational energy accounting (J/GJ/MJ) from cross-repository integration
  - Documented in `discrepancy_analysis.py` output under "interpretation" key
- [x] Add a discrepancy-analysis run that logs intermediate factors and saves a JSON artifact
  - Script: `discrepancy_analysis.py --save-results`
  - Logs: pipeline quick-check result (base/final energy ratio) + ENERGY_OPTIMIZATION_REPORT.json contents
  - Output: `results/discrepancy_*.json` with explicit note that these are not the same physical quantity
- [ ] Re-run pipeline at multiple baselines to isolate missing factors
  - Toggle/compare: with vs without VdB-Natário baseline
  - Toggle/compare: quick backreaction vs full backreaction solve
  - Toggle/compare: conservative enhancement parameters (low Q, low squeezing, N=1)

Publishable angle:
- **Verification paper** if the results reproduce.
- **Null hypothesis / parameter fragility** if they do not reproduce across small perturbations.

### 1.2 Verify QI-violation computation (Ford–Roman-style checks)

- [x] Provide a standalone verification script (`verify_qi_energy_density.py`)
- [x] Re-run QI checks with fixed seeds and save plots (`results/qi_scan.png`)
- [ ] Tighten the Ford–Roman comparison against literature formulas
  - Document sampling function and coefficient choices
  - Add explicit mapping between code quantities and literature symbols

Deliverable: a minimal script that recomputes QI integrals *and* documents the sampling function and bound used.

---

## 2) Sensitivity Analysis & Parameter Robustness (deprioritized; completed baseline)

Goal: determine whether feasibility/optimization is robust across realistic ranges and noise.

- [x] Run parameter scan and archive logs (`results/param_scan_*.log`)
- [x] Run Monte Carlo and sensitivity scans and archive outputs (`results/sensitivity_analysis_*.json` + plots)
- [ ] Extend sensitivity only as needed to support Task 1.1 (e.g., broaden ranges to find failure boundaries)

Publishable angle:
- “Robustness (or fragility) of LQG-enhanced warp-bubble optimizations.”

---

## 3) Backreaction: Linear vs Nonlinear / Iterative Coupling

The repo mentions linear backreaction (~15% reduction). Upgrade this into a testable, convergent iterative loop.

- [x] Locate backreaction implementation (`src/warp_qft/backreaction_solver.py`)
- [x] Implement a nonlinear/iterative coupling mode
  - Added `apply_backreaction_correction_iterative(...)` in `src/warp_qft/backreaction_solver.py`
  - Outer loop scales stress-energy by current energy estimate; convergence on relative energy delta
  - Standalone runner: `backreaction_iterative_experiment.py --save-results --save-plots`
  - Example artifacts: `results/backreaction_iterative_*.json` and `.png`
- [x] Integrate the iterative mode into the pipeline (toggle via config/flag)
  - Config flags: `backreaction_iterative`, `backreaction_outer_iterations`, `backreaction_relative_energy_tolerance`
  - CLI flags: `--backreaction-iterative`, `--backreaction-outer-iters`, `--backreaction-rel-tol`

Publishable angle:
- **Null result** if nonlinear/iterative coupling removes feasibility.
- **Methods** if a stable convergent solver is demonstrated.

---

## 4) Toward 3+1D (Scoped and Honest)

A full 3+1D evolution is likely out of scope short-term; do the smallest honest step that adds value.

- [x] Add `toy_evolution.py` (toy 1D/2D time evolution)
  - Simple reaction-diffusion PDE driven by negative energy density profile
  - Saves plots and JSON to `results/` with timestamps (`--save-results`, `--save-plots`)
  - Explicit non-claims documented in JSON output: no constrained 3+1 GR, no gauge conditions
  - Example artifacts: `results/toy_evolution_*.json` and `.png`

Publishable angle:
- “Failure modes / instability signatures under time evolution.”

---

## 5) Quantum-Optics Analogies (Squeezing) & Causality Checks

- [x] Verify squeezing model (currently effective-factor based)
- [x] Add coarse causality/CTC screening
  - Added `src/warp_qft/causality.py` with `screen_spherical_metric(...)` helper
  - Checks: signature violations (g_tt >= 0, g_rr <= 0), nonfinite values, null-geodesic slopes
  - Standalone runner: `causality_screen.py <input.json> --save-results`
  - Integrated into `toy_evolution.py` output; example: `results/causality_screen_*.json`
  - (QuTiP-based squeezing micro-model deferred; effective model sufficient for current scope)

Publishable angle:
- “Causality constraints in polymer-enhanced warp metrics” (likely null/constraints-heavy).

---

## 6) Benchmark Against Literature / Known Bounds

- [ ] Add a comparison table in docs
  - what bounds are being used
  - what integral/averaging procedure is applied
  - parameter mapping between code and literature
- [ ] Ensure the paper-style narrative acknowledges known objections and limitations

Deliverable: a small “Methods & limitations” doc section suitable for arXiv.

---

## Working Notes (keep updated)

- Current recommended entrypoint: `run_enhanced_lqg_pipeline.py`
- Existing artifacts in repo root worth reviewing:
  - `enhanced_pipeline_results.json`
  - `ENERGY_OPTIMIZATION_REPORT.json`
  - `thorough_scan_results.json`

Recommended run discipline:
- Run in the same environment as `results/REPRODUCIBILITY.md`.
- Prefer scripts with `--save-results` / `--save-plots` and timestamped filenames.
- Treat all “feasible” claims as *computational exploration* until nonlinear backreaction + stability checks are completed.

